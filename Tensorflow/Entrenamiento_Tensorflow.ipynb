{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5e640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp310-cp310-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp310-cp310-win_amd64.whl (331.7 MB)\n",
      "   ---------------------------------------- 0.0/331.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 8.9/331.7 MB 50.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 21.8/331.7 MB 59.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 23.1/331.7 MB 40.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 25.4/331.7 MB 31.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 29.6/331.7 MB 28.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 32.2/331.7 MB 25.9 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 34.9/331.7 MB 24.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 38.0/331.7 MB 23.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 40.6/331.7 MB 21.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 43.0/331.7 MB 20.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 45.1/331.7 MB 19.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 47.2/331.7 MB 18.9 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 49.5/331.7 MB 18.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 51.9/331.7 MB 17.7 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 54.3/331.7 MB 17.3 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 56.9/331.7 MB 16.9 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 59.5/331.7 MB 16.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 62.1/331.7 MB 16.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 65.0/331.7 MB 16.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 67.4/331.7 MB 16.0 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 70.3/331.7 MB 15.8 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 73.1/331.7 MB 15.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 76.5/331.7 MB 15.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 78.9/331.7 MB 15.6 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 81.5/331.7 MB 15.4 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 83.9/331.7 MB 15.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 86.5/331.7 MB 15.2 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 89.1/331.7 MB 15.0 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 92.0/331.7 MB 15.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 94.9/331.7 MB 15.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 97.8/331.7 MB 14.9 MB/s eta 0:00:16\n",
      "   ----------- --------------------------- 100.9/331.7 MB 14.9 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 103.8/331.7 MB 14.8 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 107.0/331.7 MB 14.8 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 109.3/331.7 MB 14.7 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 111.7/331.7 MB 14.6 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 114.0/331.7 MB 14.5 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 116.7/331.7 MB 14.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 119.3/331.7 MB 14.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 121.9/331.7 MB 14.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 124.8/331.7 MB 14.3 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 127.7/331.7 MB 14.3 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 130.5/331.7 MB 14.3 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 133.4/331.7 MB 14.3 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 136.8/331.7 MB 14.3 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 140.0/331.7 MB 14.3 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 142.1/331.7 MB 14.2 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 143.9/331.7 MB 14.1 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 145.5/331.7 MB 14.0 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 147.3/331.7 MB 13.8 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 149.2/331.7 MB 13.7 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 151.3/331.7 MB 13.7 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 153.4/331.7 MB 13.6 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 155.7/331.7 MB 13.6 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 158.3/331.7 MB 13.5 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 160.7/331.7 MB 13.5 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 163.1/331.7 MB 13.4 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 165.7/331.7 MB 13.4 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 168.3/331.7 MB 13.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 170.9/331.7 MB 13.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 174.1/331.7 MB 13.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 176.9/331.7 MB 13.4 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 180.1/331.7 MB 13.4 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 183.2/331.7 MB 13.4 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 186.4/331.7 MB 13.5 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 189.3/331.7 MB 13.5 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 192.7/331.7 MB 13.5 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 196.1/331.7 MB 13.5 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 199.8/331.7 MB 13.6 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 203.4/331.7 MB 13.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 207.1/331.7 MB 13.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 211.0/331.7 MB 13.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 214.4/331.7 MB 13.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 216.8/331.7 MB 13.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 217.6/331.7 MB 13.6 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 218.4/331.7 MB 13.5 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 219.2/331.7 MB 13.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 220.2/331.7 MB 13.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 221.2/331.7 MB 13.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 222.3/331.7 MB 13.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 223.6/331.7 MB 12.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 224.9/331.7 MB 12.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 226.5/331.7 MB 12.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 227.8/331.7 MB 12.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 229.4/331.7 MB 12.7 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 231.2/331.7 MB 12.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 233.0/331.7 MB 12.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 234.9/331.7 MB 12.5 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 237.0/331.7 MB 12.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 239.1/331.7 MB 12.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 241.2/331.7 MB 12.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 243.5/331.7 MB 12.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 246.2/331.7 MB 12.4 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 248.8/331.7 MB 12.4 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 251.4/331.7 MB 12.4 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 254.0/331.7 MB 12.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 257.2/331.7 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 260.0/331.7 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 262.7/331.7 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 265.8/331.7 MB 12.3 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 269.0/331.7 MB 12.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 272.4/331.7 MB 12.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 275.8/331.7 MB 12.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 279.4/331.7 MB 12.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 283.1/331.7 MB 11.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 286.8/331.7 MB 12.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 290.5/331.7 MB 12.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 294.1/331.7 MB 12.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 298.3/331.7 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 302.3/331.7 MB 12.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 306.2/331.7 MB 12.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 310.1/331.7 MB 12.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 314.0/331.7 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 318.8/331.7 MB 12.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 322.7/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  325.1/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  327.4/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  329.8/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.6/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.6/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.6/331.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.7/331.7 MB 12.2 MB/s  0:00:25\n",
      "Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 11.4 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp310-cp310-win_amd64.whl (210 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 2.6/5.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 13.0 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp310-cp310-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 12.9 MB/s  0:00:00\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 11.1 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 15.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.3/26.4 MB 14.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.4/26.4 MB 15.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.6/26.4 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.4 MB 15.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 14.3 MB/s  0:00:01\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp310-cp310-win_amd64.whl (60 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp310-cp310-win_amd64.whl (302 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   - --------------------------------------  1/21 [libclang]\n",
      "   --- ------------------------------------  2/21 [flatbuffers]\n",
      "   ----- ----------------------------------  3/21 [wrapt]\n",
      "   ------- --------------------------------  4/21 [wheel]\n",
      "   ------- --------------------------------  4/21 [wheel]\n",
      "   ------- --------------------------------  4/21 [wheel]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "  Attempting uninstall: protobuf\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "    Found existing installation: protobuf 4.25.8\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "    Uninstalling protobuf-4.25.8:\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "      Successfully uninstalled protobuf-4.25.8\n",
      "   --------- ------------------------------  5/21 [werkzeug]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   ------------- --------------------------  7/21 [protobuf]\n",
      "   --------------- ------------------------  8/21 [optree]\n",
      "   --------------- ------------------------  8/21 [optree]\n",
      "   ----------------- ----------------------  9/21 [opt_einsum]\n",
      "   ----------------- ----------------------  9/21 [opt_einsum]\n",
      "   ----------------- ----------------------  9/21 [opt_einsum]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   -------------------- ------------------- 11/21 [markdown]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ---------------------- ----------------- 12/21 [h5py]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   ------------------------ --------------- 13/21 [grpcio]\n",
      "   -------------------------- ------------- 14/21 [google_pasta]\n",
      "   -------------------------- ------------- 14/21 [google_pasta]\n",
      "   ---------------------------- ----------- 15/21 [gast]\n",
      "   ------------------------------ --------- 16/21 [absl-py]\n",
      "   ------------------------------ --------- 16/21 [absl-py]\n",
      "   ------------------------------ --------- 16/21 [absl-py]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   -------------------------------- ------- 17/21 [tensorboard]\n",
      "   ---------------------------------- ----- 18/21 [astunparse]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   ------------------------------------ --- 19/21 [keras]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   -------------------------------------- - 20/21 [tensorflow]\n",
      "   ---------------------------------------- 21/21 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.4 wheel-0.45.1 wrapt-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "open-clip-torch 2.20.0 requires protobuf<4, but you have protobuf 6.33.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install scikit-learn\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8ad68",
   "metadata": {},
   "source": [
    "## Preparacion de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752a062",
   "metadata": {},
   "source": [
    "### Separacion de Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ad1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando train data en ./TensorFlow_dataset_splits/Seco/NR_25037/train\n",
      "Guardando test data en ./TensorFlow_dataset_splits/Seco/NR_25037/test\n",
      "Guardando val data en ./TensorFlow_dataset_splits/Seco/NR_25037/val\n",
      "Guardando train data en ./TensorFlow_dataset_splits/Templado/NR_25033/train\n",
      "Guardando test data en ./TensorFlow_dataset_splits/Templado/NR_25033/test\n",
      "Guardando val data en ./TensorFlow_dataset_splits/Templado/NR_25033/val\n",
      "Guardando train data en ./TensorFlow_dataset_splits/Tropical/NR_25046/train\n",
      "Guardando test data en ./TensorFlow_dataset_splits/Tropical/NR_25046/test\n",
      "Guardando val data en ./TensorFlow_dataset_splits/Tropical/NR_25046/val\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_dict = {\n",
    "    25037: {'Clasificacion': 'Seco', 'ruta_origen': '../data/data_conagua_clasificada/Seco/NR_25037.csv', 'ruta_salida': './TensorFlow_dataset_splits/Seco/NR_25037/'},\n",
    "    25033: {'Clasificacion': 'Templado', 'ruta_origen': '../data/data_conagua_clasificada/Templado/NR_25033.csv', 'ruta_salida': './TensorFlow_dataset_splits/Templado/NR_25033/'},\n",
    "    25046: {'Clasificacion': 'Tropical', 'ruta_origen': '../data/data_conagua_clasificada/Tropical/NR_25046.csv', 'ruta_salida': './TensorFlow_dataset_splits/Tropical/NR_25046/'}\n",
    "}\n",
    "\n",
    "TRAIN_RATIO = 0.70\n",
    "TEST_RATIO = 0.20\n",
    "\n",
    "columnas_objetivo = ['PRECIP','EVAP','TMAX','TMIN']\n",
    "\n",
    "for file_id, file_info in file_dict.items():\n",
    "    ruta_origen = file_info['ruta_origen']\n",
    "    ruta_salida_base = file_info['ruta_salida']\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(ruta_origen, index_col=0, parse_dates=True).asfreq('D')\n",
    "    df = df.sort_index()\n",
    "    df = df.asfreq('D')\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    \n",
    "    train_end = int(total_rows * TRAIN_RATIO)\n",
    "    test_end = int(total_rows * (TRAIN_RATIO + TEST_RATIO))\n",
    "    \n",
    "    df_train = df.iloc[:train_end]\n",
    "    df_test = df.iloc[train_end:test_end]\n",
    "    df_val = df.iloc[test_end:]\n",
    "    \n",
    "    splits = {'train':{'df': df_train, 'ruta_salida': os.path.join(ruta_salida_base, 'train')},\n",
    "              'test': {'df': df_test, 'ruta_salida': os.path.join(ruta_salida_base, 'test')},\n",
    "              'val':  {'df': df_val, 'ruta_salida': os.path.join    (ruta_salida_base, 'val')}}\n",
    "    \n",
    "    for split_name, split_info in splits.items():\n",
    "        save_path = split_info['ruta_salida']\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        print(f\"Guardando {split_name} data en {save_path}\")\n",
    "        split_info['df'].to_csv(os.path.join(save_path, f\"{split_name}_data.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79b96c",
   "metadata": {},
   "source": [
    "### Escalado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498b4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "WINDOW_SIZE = 30 # Tamao de la ventana deslizante\n",
    "STEP_SIZE = 1    # Paso de la ventana deslizante\n",
    "COLUMNAS_OBJETIVO = ['PRECIP','EVAP','TMAX','TMIN']\n",
    "\n",
    "directorio = {\n",
    "    25037: {'Clasificacion': 'Seco', 'ruta_base': './TensorFlow_dataset_splits/Seco/NR_25037/','ruta_saliente': './Tensorflow_data_escalada/Seco/NR_25037/'},\n",
    "    25033: {'Clasificacion': 'Templado', 'ruta_base': './TensorFlow_dataset_splits/Templado/NR_25033/','ruta_saliente': './Tensorflow_data_escalada/Templado/NR_25033/'},\n",
    "    25046: {'Clasificacion': 'Tropical', 'ruta_base': './TensorFlow_dataset_splits/Tropical/NR_25046/','ruta_saliente': './Tensorflow_data_escalada/Tropical/NR_25046/'}\n",
    "}\n",
    "\n",
    "for file_id, paths in directorio.items():\n",
    "    ruta_base = paths['ruta_base']\n",
    "    ruta_salida_base = paths['ruta_saliente']\n",
    "    \n",
    "    os.makedirs(ruta_salida_base, exist_ok=True)\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        ruta_split = os.path.join(ruta_base, split, f\"{split}_data.csv\")\n",
    "        df = pd.read_csv(ruta_split, index_col=0, parse_dates=True).asfreq('D')\n",
    "        df = df[COLUMNAS_OBJETIVO].fillna(0) # Llenar NaNs con 0 para escalado\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df)\n",
    "        \n",
    "        df_scaled = pd.DataFrame(scaler.transform(df), columns = COLUMNAS_OBJETIVO, index=df.index)\n",
    "        \n",
    "        ruta_csv = os.path.join(ruta_salida_base, split,'data', f\"{split}_data_scaled.csv\")\n",
    "        os.makedirs(os.path.join(ruta_salida_base, split, 'data'), exist_ok=True)\n",
    "        df_scaled.to_csv(ruta_csv)\n",
    "        \n",
    "        ruta_scaler = os.path.join(ruta_salida_base, 'scaler')\n",
    "        \n",
    "        os.makedirs(os.path.join(ruta_scaler), exist_ok=True)\n",
    "        joblib.dump(scaler, os.path.join(ruta_scaler, f'scaler_{split}.joblib.pkl'))\n",
    "        \n",
    "        data_values = df_scaled.values\n",
    "        Xs =[]\n",
    "        \n",
    "        num_muestras = len(data_values) - WINDOW_SIZE \n",
    "        \n",
    "        if num_muestras > 0:\n",
    "            for i in range(0, len(data_values) - WINDOW_SIZE, STEP_SIZE):\n",
    "                ventana = data_values[i : (i + WINDOW_SIZE)]\n",
    "                Xs.append(ventana)\n",
    "            \n",
    "        X_tensor = np.array(Xs)\n",
    "        \n",
    "        ruta_tensor = os.path.join(ruta_salida_base, split,'tensor' ,f\"{split}_data_tensor.npy\")\n",
    "        os.makedirs(os.path.dirname(ruta_tensor), exist_ok=True)\n",
    "        np.save(ruta_tensor, X_tensor)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5ba654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " time_distributed                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                      \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m35,328\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m98,816\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " time_distributed                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                     \u001b[38;5;34m516\u001b[0m \n",
       " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                      \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para la estacin 25037...\n",
      "Epoch 1/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0387\n",
      "Epoch 1: loss improved from None to 0.01870, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 87ms/step - loss: 0.0187\n",
      "Epoch 2/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0083\n",
      "Epoch 2: loss improved from 0.01870 to 0.00800, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 0.0080\n",
      "Epoch 3/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0074\n",
      "Epoch 3: loss improved from 0.00800 to 0.00716, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0072\n",
      "Epoch 4/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0067\n",
      "Epoch 4: loss improved from 0.00716 to 0.00670, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0067\n",
      "Epoch 5/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0064\n",
      "Epoch 5: loss improved from 0.00670 to 0.00637, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 92ms/step - loss: 0.0064\n",
      "Epoch 6/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0062\n",
      "Epoch 6: loss improved from 0.00637 to 0.00614, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 92ms/step - loss: 0.0061\n",
      "Epoch 7/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0060\n",
      "Epoch 7: loss improved from 0.00614 to 0.00592, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0059\n",
      "Epoch 8/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0058\n",
      "Epoch 8: loss improved from 0.00592 to 0.00579, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0058\n",
      "Epoch 9/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0056\n",
      "Epoch 9: loss improved from 0.00579 to 0.00562, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - loss: 0.0056\n",
      "Epoch 10/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0056\n",
      "Epoch 10: loss improved from 0.00562 to 0.00550, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - loss: 0.0055\n",
      "Epoch 11/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0054\n",
      "Epoch 11: loss improved from 0.00550 to 0.00539, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0054\n",
      "Epoch 12/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0053\n",
      "Epoch 12: loss improved from 0.00539 to 0.00529, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0053\n",
      "Epoch 13/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0052\n",
      "Epoch 13: loss improved from 0.00529 to 0.00522, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0052\n",
      "Epoch 14/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0052\n",
      "Epoch 14: loss improved from 0.00522 to 0.00516, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - loss: 0.0052\n",
      "Epoch 15/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0051\n",
      "Epoch 15: loss improved from 0.00516 to 0.00506, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0051\n",
      "Epoch 16/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0050\n",
      "Epoch 16: loss improved from 0.00506 to 0.00503, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0050\n",
      "Epoch 17: loss improved from 0.00503 to 0.00498, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0049\n",
      "Epoch 18: loss improved from 0.00498 to 0.00492, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.0049\n",
      "Epoch 19/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0055\n",
      "Epoch 19: loss did not improve from 0.00492\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 99ms/step - loss: 0.0054\n",
      "Epoch 20/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0050\n",
      "Epoch 20: loss did not improve from 0.00492\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0050\n",
      "Epoch 21/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0049\n",
      "Epoch 21: loss did not improve from 0.00492\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0049\n",
      "Epoch 22/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0049\n",
      "Epoch 22: loss improved from 0.00492 to 0.00488, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0049\n",
      "Epoch 23/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0049\n",
      "Epoch 23: loss improved from 0.00488 to 0.00483, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - loss: 0.0048\n",
      "Epoch 24/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0047\n",
      "Epoch 24: loss improved from 0.00483 to 0.00480, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0048\n",
      "Epoch 25/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0047\n",
      "Epoch 25: loss improved from 0.00480 to 0.00476, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0048\n",
      "Epoch 26/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0047\n",
      "Epoch 26: loss improved from 0.00476 to 0.00473, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0047\n",
      "Epoch 27/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0047\n",
      "Epoch 27: loss improved from 0.00473 to 0.00472, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0047\n",
      "Epoch 28/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0047\n",
      "Epoch 28: loss improved from 0.00472 to 0.00470, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0047\n",
      "Epoch 29/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0047\n",
      "Epoch 29: loss improved from 0.00470 to 0.00466, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0047\n",
      "Epoch 30/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0046\n",
      "Epoch 30: loss improved from 0.00466 to 0.00464, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - loss: 0.0046\n",
      "Epoch 31/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0046\n",
      "Epoch 31: loss improved from 0.00464 to 0.00462, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0046\n",
      "Epoch 32/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0046\n",
      "Epoch 32: loss improved from 0.00462 to 0.00459, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - loss: 0.0046\n",
      "Epoch 33/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0046\n",
      "Epoch 33: loss improved from 0.00459 to 0.00457, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - loss: 0.0046\n",
      "Epoch 34/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 34: loss improved from 0.00457 to 0.00454, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0045\n",
      "Epoch 35/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0045\n",
      "Epoch 35: loss improved from 0.00454 to 0.00452, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 36/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 36: loss did not improve from 0.00452\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 37/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 37: loss improved from 0.00452 to 0.00449, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 38/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0045\n",
      "Epoch 38: loss improved from 0.00449 to 0.00447, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 39/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0045\n",
      "Epoch 39: loss improved from 0.00447 to 0.00446, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - loss: 0.0045\n",
      "Epoch 40/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0044\n",
      "Epoch 40: loss improved from 0.00446 to 0.00443, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 121ms/step - loss: 0.0044\n",
      "Epoch 41/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0044\n",
      "Epoch 41: loss improved from 0.00443 to 0.00440, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 108ms/step - loss: 0.0044\n",
      "Epoch 42/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0044\n",
      "Epoch 42: loss did not improve from 0.00440\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - loss: 0.0044\n",
      "Epoch 43/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0044\n",
      "Epoch 43: loss improved from 0.00440 to 0.00436, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - loss: 0.0044\n",
      "Epoch 44/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0043\n",
      "Epoch 44: loss improved from 0.00436 to 0.00434, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - loss: 0.0043\n",
      "Epoch 45/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0043\n",
      "Epoch 45: loss improved from 0.00434 to 0.00433, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 92ms/step - loss: 0.0043\n",
      "Epoch 46/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0043\n",
      "Epoch 46: loss improved from 0.00433 to 0.00431, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 0.0043\n",
      "Epoch 47/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0043\n",
      "Epoch 47: loss improved from 0.00431 to 0.00428, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 108ms/step - loss: 0.0043\n",
      "Epoch 48/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0043\n",
      "Epoch 48: loss did not improve from 0.00428\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - loss: 0.0043\n",
      "Epoch 49/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0043\n",
      "Epoch 49: loss improved from 0.00428 to 0.00425, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - loss: 0.0043\n",
      "Epoch 50/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0042\n",
      "Epoch 50: loss did not improve from 0.00425\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - loss: 0.0043\n",
      "Epoch 51/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0042\n",
      "Epoch 51: loss improved from 0.00425 to 0.00422, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 114ms/step - loss: 0.0042\n",
      "Epoch 52/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0042\n",
      "Epoch 52: loss improved from 0.00422 to 0.00422, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 106ms/step - loss: 0.0042\n",
      "Epoch 53/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0042\n",
      "Epoch 53: loss improved from 0.00422 to 0.00420, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 105ms/step - loss: 0.0042\n",
      "Epoch 54/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0042\n",
      "Epoch 54: loss improved from 0.00420 to 0.00418, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 103ms/step - loss: 0.0042\n",
      "Epoch 55/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0042\n",
      "Epoch 55: loss improved from 0.00418 to 0.00416, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0042\n",
      "Epoch 56/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0041\n",
      "Epoch 56: loss improved from 0.00416 to 0.00415, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - loss: 0.0041\n",
      "Epoch 57/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0041\n",
      "Epoch 57: loss improved from 0.00415 to 0.00413, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - loss: 0.0041\n",
      "Epoch 58/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0041\n",
      "Epoch 58: loss improved from 0.00413 to 0.00412, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - loss: 0.0041\n",
      "Epoch 59/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0041\n",
      "Epoch 59: loss improved from 0.00412 to 0.00412, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step - loss: 0.0041\n",
      "Epoch 60/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0041\n",
      "Epoch 60: loss improved from 0.00412 to 0.00410, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - loss: 0.0041\n",
      "Epoch 61/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0041\n",
      "Epoch 61: loss did not improve from 0.00410\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - loss: 0.0041\n",
      "Epoch 62/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0041\n",
      "Epoch 62: loss improved from 0.00410 to 0.00407, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - loss: 0.0041\n",
      "Epoch 63/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0040\n",
      "Epoch 63: loss improved from 0.00407 to 0.00406, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - loss: 0.0041\n",
      "Epoch 64/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0041\n",
      "Epoch 64: loss did not improve from 0.00406\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - loss: 0.0041\n",
      "Epoch 65/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0041\n",
      "Epoch 65: loss improved from 0.00406 to 0.00405, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - loss: 0.0040\n",
      "Epoch 66/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0040\n",
      "Epoch 66: loss improved from 0.00405 to 0.00404, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - loss: 0.0040\n",
      "Epoch 67/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0040\n",
      "Epoch 67: loss improved from 0.00404 to 0.00402, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 103ms/step - loss: 0.0040\n",
      "Epoch 68/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0040 \n",
      "Epoch 68: loss improved from 0.00402 to 0.00400, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.0040\n",
      "Epoch 69/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0040\n",
      "Epoch 69: loss did not improve from 0.00400\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - loss: 0.0040\n",
      "Epoch 70/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0040\n",
      "Epoch 70: loss improved from 0.00400 to 0.00399, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - loss: 0.0040\n",
      "Epoch 71/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0040\n",
      "Epoch 71: loss improved from 0.00399 to 0.00398, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - loss: 0.0040\n",
      "Epoch 72/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0040\n",
      "Epoch 72: loss improved from 0.00398 to 0.00397, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step - loss: 0.0040\n",
      "Epoch 73/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0039\n",
      "Epoch 73: loss improved from 0.00397 to 0.00396, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step - loss: 0.0040\n",
      "Epoch 74/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0039\n",
      "Epoch 74: loss improved from 0.00396 to 0.00394, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - loss: 0.0039\n",
      "Epoch 75/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0040\n",
      "Epoch 75: loss did not improve from 0.00394\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - loss: 0.0039\n",
      "Epoch 76/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0039\n",
      "Epoch 76: loss improved from 0.00394 to 0.00394, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 78ms/step - loss: 0.0039\n",
      "Epoch 77/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0039\n",
      "Epoch 77: loss improved from 0.00394 to 0.00392, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 77ms/step - loss: 0.0039\n",
      "Epoch 78/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0039\n",
      "Epoch 78: loss improved from 0.00392 to 0.00391, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - loss: 0.0039\n",
      "Epoch 79/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0039\n",
      "Epoch 79: loss improved from 0.00391 to 0.00390, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - loss: 0.0039\n",
      "Epoch 80/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0039\n",
      "Epoch 80: loss did not improve from 0.00390\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 79ms/step - loss: 0.0039\n",
      "Epoch 81/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0039\n",
      "Epoch 81: loss improved from 0.00390 to 0.00388, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 76ms/step - loss: 0.0039\n",
      "Epoch 82/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0039\n",
      "Epoch 82: loss did not improve from 0.00388\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - loss: 0.0039\n",
      "Epoch 83/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0039\n",
      "Epoch 83: loss improved from 0.00388 to 0.00387, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - loss: 0.0039\n",
      "Epoch 84/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0039\n",
      "Epoch 84: loss improved from 0.00387 to 0.00386, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 78ms/step - loss: 0.0039\n",
      "Epoch 85/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0039\n",
      "Epoch 85: loss improved from 0.00386 to 0.00385, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 69ms/step - loss: 0.0038\n",
      "Epoch 86/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 86: loss did not improve from 0.00385\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 87/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0038\n",
      "Epoch 87: loss improved from 0.00385 to 0.00382, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - loss: 0.0038\n",
      "Epoch 88/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0038\n",
      "Epoch 88: loss did not improve from 0.00382\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - loss: 0.0038\n",
      "Epoch 89/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 89: loss did not improve from 0.00382\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 90/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 90: loss improved from 0.00382 to 0.00382, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 63ms/step - loss: 0.0038\n",
      "Epoch 91/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0038\n",
      "Epoch 91: loss improved from 0.00382 to 0.00380, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - loss: 0.0038\n",
      "Epoch 92/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0038\n",
      "Epoch 92: loss improved from 0.00380 to 0.00379, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - loss: 0.0038\n",
      "Epoch 93/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0038\n",
      "Epoch 93: loss improved from 0.00379 to 0.00379, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - loss: 0.0038\n",
      "Epoch 94/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 94: loss improved from 0.00379 to 0.00379, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 95/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 95: loss improved from 0.00379 to 0.00377, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 96/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0038\n",
      "Epoch 96: loss improved from 0.00377 to 0.00375, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - loss: 0.0038\n",
      "Epoch 97/100\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0037\n",
      "Epoch 97: loss did not improve from 0.00375\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 98/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 98: loss did not improve from 0.00375\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - loss: 0.0038\n",
      "Epoch 99/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0037\n",
      "Epoch 99: loss improved from 0.00375 to 0.00375, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - loss: 0.0038\n",
      "Epoch 100/100\n",
      "\u001b[1m289/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0038\n",
      "Epoch 100: loss improved from 0.00375 to 0.00374, saving model to ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n",
      "\u001b[1m290/290\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - loss: 0.0037\n",
      "Modelo entrenado y guardado en ./Modelos_Tensorflow/Seco/NR_25037/AE_BiLSTM_estacion_25037.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " time_distributed                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                      \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m35,328\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m98,816\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " time_distributed                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                     \u001b[38;5;34m516\u001b[0m \n",
       " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                      \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para la estacin 25033...\n",
      "Epoch 1/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0467\n",
      "Epoch 1: loss improved from None to 0.02178, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - loss: 0.0218\n",
      "Epoch 2/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0093\n",
      "Epoch 2: loss improved from 0.02178 to 0.00884, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - loss: 0.0088\n",
      "Epoch 3/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0077\n",
      "Epoch 3: loss improved from 0.00884 to 0.00765, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - loss: 0.0076\n",
      "Epoch 4/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0072\n",
      "Epoch 4: loss improved from 0.00765 to 0.00709, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - loss: 0.0071\n",
      "Epoch 5/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0068\n",
      "Epoch 5: loss improved from 0.00709 to 0.00671, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - loss: 0.0067\n",
      "Epoch 6/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0065\n",
      "Epoch 6: loss improved from 0.00671 to 0.00639, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - loss: 0.0064\n",
      "Epoch 7/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0062\n",
      "Epoch 7: loss improved from 0.00639 to 0.00618, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - loss: 0.0062\n",
      "Epoch 8/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0060\n",
      "Epoch 8: loss improved from 0.00618 to 0.00600, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - loss: 0.0060\n",
      "Epoch 9/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0059\n",
      "Epoch 9: loss improved from 0.00600 to 0.00584, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - loss: 0.0058\n",
      "Epoch 10/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0057\n",
      "Epoch 10: loss improved from 0.00584 to 0.00568, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 91ms/step - loss: 0.0057\n",
      "Epoch 11/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0056\n",
      "Epoch 11: loss improved from 0.00568 to 0.00556, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - loss: 0.0056\n",
      "Epoch 12/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0055\n",
      "Epoch 12: loss improved from 0.00556 to 0.00543, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - loss: 0.0054\n",
      "Epoch 13/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0053\n",
      "Epoch 13: loss improved from 0.00543 to 0.00532, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - loss: 0.0053\n",
      "Epoch 14/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0052\n",
      "Epoch 14: loss improved from 0.00532 to 0.00523, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - loss: 0.0052\n",
      "Epoch 15/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0051\n",
      "Epoch 15: loss improved from 0.00523 to 0.00515, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - loss: 0.0052\n",
      "Epoch 16/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0051\n",
      "Epoch 16: loss improved from 0.00515 to 0.00507, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - loss: 0.0051\n",
      "Epoch 17/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0051\n",
      "Epoch 17: loss improved from 0.00507 to 0.00501, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - loss: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0050\n",
      "Epoch 18: loss improved from 0.00501 to 0.00495, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.0049\n",
      "Epoch 19/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0049\n",
      "Epoch 19: loss improved from 0.00495 to 0.00487, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.0049\n",
      "Epoch 20/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0048\n",
      "Epoch 20: loss improved from 0.00487 to 0.00483, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.0048\n",
      "Epoch 21/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0048\n",
      "Epoch 21: loss improved from 0.00483 to 0.00481, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0048\n",
      "Epoch 22/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0047\n",
      "Epoch 22: loss improved from 0.00481 to 0.00473, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0047\n",
      "Epoch 23/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0047\n",
      "Epoch 23: loss improved from 0.00473 to 0.00470, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - loss: 0.0047\n",
      "Epoch 24/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0047\n",
      "Epoch 24: loss improved from 0.00470 to 0.00468, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - loss: 0.0047\n",
      "Epoch 25/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0047\n",
      "Epoch 25: loss improved from 0.00468 to 0.00464, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 62ms/step - loss: 0.0046\n",
      "Epoch 26/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0046\n",
      "Epoch 26: loss improved from 0.00464 to 0.00461, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - loss: 0.0046\n",
      "Epoch 27/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0046\n",
      "Epoch 27: loss improved from 0.00461 to 0.00460, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 62ms/step - loss: 0.0046\n",
      "Epoch 28/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0045\n",
      "Epoch 28: loss improved from 0.00460 to 0.00454, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - loss: 0.0045\n",
      "Epoch 29/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0046\n",
      "Epoch 29: loss improved from 0.00454 to 0.00451, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - loss: 0.0045\n",
      "Epoch 30/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0045\n",
      "Epoch 30: loss improved from 0.00451 to 0.00451, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - loss: 0.0045\n",
      "Epoch 31/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0044\n",
      "Epoch 31: loss improved from 0.00451 to 0.00447, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - loss: 0.0045\n",
      "Epoch 32/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0045\n",
      "Epoch 32: loss improved from 0.00447 to 0.00446, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - loss: 0.0045\n",
      "Epoch 33/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0044\n",
      "Epoch 33: loss improved from 0.00446 to 0.00443, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0044\n",
      "Epoch 34/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0044\n",
      "Epoch 34: loss improved from 0.00443 to 0.00440, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 68ms/step - loss: 0.0044\n",
      "Epoch 35/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0044\n",
      "Epoch 35: loss improved from 0.00440 to 0.00439, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.0044\n",
      "Epoch 36/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0044\n",
      "Epoch 36: loss improved from 0.00439 to 0.00437, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - loss: 0.0044\n",
      "Epoch 37/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0044\n",
      "Epoch 37: loss improved from 0.00437 to 0.00435, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.0043\n",
      "Epoch 38/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0043\n",
      "Epoch 38: loss improved from 0.00435 to 0.00432, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.0043\n",
      "Epoch 39/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0043\n",
      "Epoch 39: loss did not improve from 0.00432\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.0043\n",
      "Epoch 40/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0043\n",
      "Epoch 40: loss improved from 0.00432 to 0.00430, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 85ms/step - loss: 0.0043\n",
      "Epoch 41/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0043\n",
      "Epoch 41: loss improved from 0.00430 to 0.00428, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.0043\n",
      "Epoch 42/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0043\n",
      "Epoch 42: loss did not improve from 0.00428\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - loss: 0.0043\n",
      "Epoch 43/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0043\n",
      "Epoch 43: loss improved from 0.00428 to 0.00424, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - loss: 0.0042\n",
      "Epoch 44/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0043\n",
      "Epoch 44: loss improved from 0.00424 to 0.00423, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.0042\n",
      "Epoch 45/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0042\n",
      "Epoch 45: loss improved from 0.00423 to 0.00420, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.0042\n",
      "Epoch 46/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0042\n",
      "Epoch 46: loss improved from 0.00420 to 0.00420, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - loss: 0.0042\n",
      "Epoch 47/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0042\n",
      "Epoch 47: loss improved from 0.00420 to 0.00418, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.0042\n",
      "Epoch 48/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0042\n",
      "Epoch 48: loss improved from 0.00418 to 0.00417, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0042\n",
      "Epoch 49/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0042\n",
      "Epoch 49: loss improved from 0.00417 to 0.00415, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - loss: 0.0042\n",
      "Epoch 50/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0042\n",
      "Epoch 50: loss improved from 0.00415 to 0.00413, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - loss: 0.0041\n",
      "Epoch 51/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041\n",
      "Epoch 51: loss improved from 0.00413 to 0.00412, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - loss: 0.0041\n",
      "Epoch 52/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041\n",
      "Epoch 52: loss improved from 0.00412 to 0.00409, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - loss: 0.0041\n",
      "Epoch 53/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0041\n",
      "Epoch 53: loss improved from 0.00409 to 0.00409, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 63ms/step - loss: 0.0041\n",
      "Epoch 54/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0041\n",
      "Epoch 54: loss did not improve from 0.00409\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 65ms/step - loss: 0.0041\n",
      "Epoch 55/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0040\n",
      "Epoch 55: loss improved from 0.00409 to 0.00404, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0040\n",
      "Epoch 56/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0040\n",
      "Epoch 56: loss improved from 0.00404 to 0.00403, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0040\n",
      "Epoch 57/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0040\n",
      "Epoch 57: loss did not improve from 0.00403\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - loss: 0.0040\n",
      "Epoch 58/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0040\n",
      "Epoch 58: loss improved from 0.00403 to 0.00403, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0040\n",
      "Epoch 59/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0040\n",
      "Epoch 59: loss improved from 0.00403 to 0.00401, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 65ms/step - loss: 0.0040\n",
      "Epoch 60/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0040\n",
      "Epoch 60: loss improved from 0.00401 to 0.00399, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - loss: 0.0040\n",
      "Epoch 61/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0040\n",
      "Epoch 61: loss did not improve from 0.00399\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 69ms/step - loss: 0.0040\n",
      "Epoch 62/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0039\n",
      "Epoch 62: loss improved from 0.00399 to 0.00396, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - loss: 0.0040\n",
      "Epoch 63/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0039\n",
      "Epoch 63: loss improved from 0.00396 to 0.00395, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 64ms/step - loss: 0.0039\n",
      "Epoch 64/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0039\n",
      "Epoch 64: loss improved from 0.00395 to 0.00394, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.0039\n",
      "Epoch 65/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 65: loss did not improve from 0.00394\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - loss: 0.0039\n",
      "Epoch 66/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0039\n",
      "Epoch 66: loss improved from 0.00394 to 0.00393, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - loss: 0.0039\n",
      "Epoch 67/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0039\n",
      "Epoch 67: loss improved from 0.00393 to 0.00391, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - loss: 0.0039\n",
      "Epoch 68/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0039\n",
      "Epoch 68: loss improved from 0.00391 to 0.00391, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - loss: 0.0039\n",
      "Epoch 69/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0039\n",
      "Epoch 69: loss improved from 0.00391 to 0.00388, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 70/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 70: loss improved from 0.00388 to 0.00387, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - loss: 0.0039\n",
      "Epoch 71/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0038\n",
      "Epoch 71: loss did not improve from 0.00387\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 57ms/step - loss: 0.0039\n",
      "Epoch 72/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 72: loss improved from 0.00387 to 0.00385, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 73/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 73: loss improved from 0.00385 to 0.00384, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - loss: 0.0038\n",
      "Epoch 74/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0038\n",
      "Epoch 74: loss did not improve from 0.00384\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - loss: 0.0038\n",
      "Epoch 75/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0038\n",
      "Epoch 75: loss improved from 0.00384 to 0.00381, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - loss: 0.0038\n",
      "Epoch 76/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0039\n",
      "Epoch 76: loss did not improve from 0.00381\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 77/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0038\n",
      "Epoch 77: loss improved from 0.00381 to 0.00379, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0038\n",
      "Epoch 78/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0038\n",
      "Epoch 78: loss did not improve from 0.00379\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - loss: 0.0038\n",
      "Epoch 79/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0037\n",
      "Epoch 79: loss improved from 0.00379 to 0.00378, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 0.0038\n",
      "Epoch 80/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 80: loss improved from 0.00378 to 0.00376, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 81/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 81: loss did not improve from 0.00376\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 82/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0037\n",
      "Epoch 82: loss did not improve from 0.00376\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 83/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0037\n",
      "Epoch 83: loss did not improve from 0.00376\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 84/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0037\n",
      "Epoch 84: loss improved from 0.00376 to 0.00375, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 0.0038\n",
      "Epoch 85/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 85: loss improved from 0.00375 to 0.00373, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 86/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 86: loss improved from 0.00373 to 0.00372, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 87/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 87: loss improved from 0.00372 to 0.00371, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 88/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0037\n",
      "Epoch 88: loss did not improve from 0.00371\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0037\n",
      "Epoch 89/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 89: loss improved from 0.00371 to 0.00368, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 90/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 90: loss did not improve from 0.00368\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 91/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 91: loss did not improve from 0.00368\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 92/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 92: loss did not improve from 0.00368\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 93/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 93: loss improved from 0.00368 to 0.00367, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0037\n",
      "Epoch 94/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 94: loss improved from 0.00367 to 0.00366, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 95/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 95: loss improved from 0.00366 to 0.00366, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 96/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 96: loss improved from 0.00366 to 0.00366, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0037\n",
      "Epoch 97/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Epoch 97: loss improved from 0.00366 to 0.00364, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Epoch 98/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Epoch 98: loss improved from 0.00364 to 0.00364, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Epoch 99/100\n",
      "\u001b[1m257/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0036\n",
      "Epoch 99: loss improved from 0.00364 to 0.00363, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 0.0036\n",
      "Epoch 100/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Epoch 100: loss improved from 0.00363 to 0.00362, saving model to ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0036\n",
      "Modelo entrenado y guardado en ./Modelos_Tensorflow/Templado/NR_25033/AE_BiLSTM_estacion_25033.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " time_distributed                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                      \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m35,328\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m98,816\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " time_distributed                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)                     \u001b[38;5;34m516\u001b[0m \n",
       " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                      \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,660</span> (526.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,660\u001b[0m (526.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para la estacin 25046...\n",
      "Epoch 1/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0373\n",
      "Epoch 1: loss improved from None to 0.01712, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 0.0171\n",
      "Epoch 2/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0074\n",
      "Epoch 2: loss improved from 0.01712 to 0.00702, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0070\n",
      "Epoch 3/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0064\n",
      "Epoch 3: loss improved from 0.00702 to 0.00629, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0063\n",
      "Epoch 4/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0060\n",
      "Epoch 4: loss improved from 0.00629 to 0.00593, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0059\n",
      "Epoch 5/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0057\n",
      "Epoch 5: loss improved from 0.00593 to 0.00568, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0057\n",
      "Epoch 6/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0055\n",
      "Epoch 6: loss improved from 0.00568 to 0.00549, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.0055\n",
      "Epoch 7/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0054\n",
      "Epoch 7: loss improved from 0.00549 to 0.00532, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0053\n",
      "Epoch 8/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0052\n",
      "Epoch 8: loss improved from 0.00532 to 0.00518, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0052\n",
      "Epoch 9/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0051\n",
      "Epoch 9: loss improved from 0.00518 to 0.00505, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0050\n",
      "Epoch 10: loss improved from 0.00505 to 0.00491, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0049\n",
      "Epoch 11/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0049\n",
      "Epoch 11: loss improved from 0.00491 to 0.00481, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0048\n",
      "Epoch 12/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0048\n",
      "Epoch 12: loss improved from 0.00481 to 0.00474, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0047\n",
      "Epoch 13/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0047\n",
      "Epoch 13: loss improved from 0.00474 to 0.00465, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0047\n",
      "Epoch 14/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0046\n",
      "Epoch 14: loss improved from 0.00465 to 0.00458, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0046\n",
      "Epoch 15/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0046\n",
      "Epoch 15: loss improved from 0.00458 to 0.00453, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0045\n",
      "Epoch 16/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0045\n",
      "Epoch 16: loss improved from 0.00453 to 0.00447, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0045\n",
      "Epoch 17/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0044\n",
      "Epoch 17: loss improved from 0.00447 to 0.00442, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0044\n",
      "Epoch 18/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0043\n",
      "Epoch 18: loss improved from 0.00442 to 0.00437, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0044\n",
      "Epoch 19/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0043\n",
      "Epoch 19: loss improved from 0.00437 to 0.00434, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0043\n",
      "Epoch 20/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0043\n",
      "Epoch 20: loss improved from 0.00434 to 0.00429, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0043\n",
      "Epoch 21/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0043\n",
      "Epoch 21: loss improved from 0.00429 to 0.00425, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0042\n",
      "Epoch 22/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0042\n",
      "Epoch 22: loss improved from 0.00425 to 0.00422, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0042\n",
      "Epoch 23/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0042\n",
      "Epoch 23: loss improved from 0.00422 to 0.00419, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0042\n",
      "Epoch 24/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0042\n",
      "Epoch 24: loss improved from 0.00419 to 0.00415, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0042\n",
      "Epoch 25/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0041\n",
      "Epoch 25: loss improved from 0.00415 to 0.00412, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0041\n",
      "Epoch 26/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0041\n",
      "Epoch 26: loss improved from 0.00412 to 0.00409, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0041\n",
      "Epoch 27/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 27: loss improved from 0.00409 to 0.00405, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 28/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 28: loss improved from 0.00405 to 0.00402, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0040\n",
      "Epoch 29/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 29: loss improved from 0.00402 to 0.00400, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 30/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0040\n",
      "Epoch 30: loss improved from 0.00400 to 0.00397, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0040\n",
      "Epoch 31/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0040\n",
      "Epoch 31: loss improved from 0.00397 to 0.00397, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0040\n",
      "Epoch 32/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0039\n",
      "Epoch 32: loss improved from 0.00397 to 0.00392, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0039\n",
      "Epoch 33/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0039\n",
      "Epoch 33: loss improved from 0.00392 to 0.00389, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0039\n",
      "Epoch 34/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0039\n",
      "Epoch 34: loss improved from 0.00389 to 0.00387, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0039\n",
      "Epoch 35/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0039\n",
      "Epoch 35: loss improved from 0.00387 to 0.00386, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0039\n",
      "Epoch 36/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0039\n",
      "Epoch 36: loss improved from 0.00386 to 0.00383, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0038\n",
      "Epoch 37/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 37: loss improved from 0.00383 to 0.00382, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 38/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 38: loss improved from 0.00382 to 0.00380, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 39/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 39: loss improved from 0.00380 to 0.00379, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0038\n",
      "Epoch 40/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0038\n",
      "Epoch 40: loss improved from 0.00379 to 0.00378, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0038\n",
      "Epoch 41/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0038\n",
      "Epoch 41: loss improved from 0.00378 to 0.00375, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.0038\n",
      "Epoch 42/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0037\n",
      "Epoch 42: loss improved from 0.00375 to 0.00374, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0037\n",
      "Epoch 43/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 43: loss improved from 0.00374 to 0.00372, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 44/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 44: loss did not improve from 0.00372\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 45/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0037\n",
      "Epoch 45: loss improved from 0.00372 to 0.00368, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0037\n",
      "Epoch 46/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 46: loss did not improve from 0.00368\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 47/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 47: loss improved from 0.00368 to 0.00367, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 48/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 48: loss improved from 0.00367 to 0.00365, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0037\n",
      "Epoch 49/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0036\n",
      "Epoch 49: loss improved from 0.00365 to 0.00363, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0036\n",
      "Epoch 50/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 50: loss improved from 0.00363 to 0.00363, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 51/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0036\n",
      "Epoch 51: loss did not improve from 0.00363\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0036\n",
      "Epoch 52/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 52: loss did not improve from 0.00363\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 53/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0036\n",
      "Epoch 53: loss improved from 0.00363 to 0.00358, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.0036\n",
      "Epoch 54/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 54: loss improved from 0.00358 to 0.00357, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 55/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 55: loss improved from 0.00357 to 0.00356, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.0036\n",
      "Epoch 56/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 56: loss improved from 0.00356 to 0.00355, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 57/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 57: loss improved from 0.00355 to 0.00354, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 58/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 58: loss improved from 0.00354 to 0.00352, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 59/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 59: loss improved from 0.00352 to 0.00352, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 60/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 60: loss improved from 0.00352 to 0.00350, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 61/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 61: loss did not improve from 0.00350\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0036\n",
      "Epoch 62/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 62: loss improved from 0.00350 to 0.00350, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 63/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 63: loss improved from 0.00350 to 0.00347, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 64/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 64: loss improved from 0.00347 to 0.00347, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 65/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 65: loss improved from 0.00347 to 0.00345, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0035\n",
      "Epoch 66/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 66: loss did not improve from 0.00345\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 67/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0035\n",
      "Epoch 67: loss improved from 0.00345 to 0.00343, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 68/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 68: loss improved from 0.00343 to 0.00342, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 69/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 69: loss improved from 0.00342 to 0.00342, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 70/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 70: loss improved from 0.00342 to 0.00341, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 71/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 71: loss did not improve from 0.00341\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 72/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 72: loss improved from 0.00341 to 0.00339, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 73/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 73: loss improved from 0.00339 to 0.00338, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 74/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 74: loss improved from 0.00338 to 0.00338, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 75/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 75: loss improved from 0.00338 to 0.00336, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 76/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 76: loss improved from 0.00336 to 0.00336, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0034\n",
      "Epoch 77/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 77: loss improved from 0.00336 to 0.00335, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 78/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 78: loss improved from 0.00335 to 0.00334, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 79/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0034\n",
      "Epoch 79: loss improved from 0.00334 to 0.00333, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 80/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 80: loss improved from 0.00333 to 0.00332, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 81/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 81: loss improved from 0.00332 to 0.00332, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 82/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 82: loss improved from 0.00332 to 0.00332, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 83/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 83: loss improved from 0.00332 to 0.00330, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 84/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 84: loss improved from 0.00330 to 0.00329, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 85/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 85: loss did not improve from 0.00329\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 86/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 86: loss improved from 0.00329 to 0.00329, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 87/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 87: loss improved from 0.00329 to 0.00327, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 88/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 88: loss improved from 0.00327 to 0.00326, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 89/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 89: loss improved from 0.00326 to 0.00326, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 90/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 90: loss improved from 0.00326 to 0.00325, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 91/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033\n",
      "Epoch 91: loss improved from 0.00325 to 0.00325, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 92/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 92: loss did not improve from 0.00325\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0033\n",
      "Epoch 93/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 93: loss improved from 0.00325 to 0.00324, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 94/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 94: loss improved from 0.00324 to 0.00322, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 95/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 95: loss did not improve from 0.00322\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 96/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 96: loss improved from 0.00322 to 0.00321, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 97/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 97: loss improved from 0.00321 to 0.00321, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 98/100\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 98: loss improved from 0.00321 to 0.00320, saving model to ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.0032\n",
      "Epoch 99/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 99: loss did not improve from 0.00320\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 100/100\n",
      "\u001b[1m333/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Epoch 100: loss did not improve from 0.00320\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.0032\n",
      "Modelo entrenado y guardado en ./Modelos_Tensorflow/Tropical/NR_25046/AE_BiLSTM_estacion_25046.keras\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INPUT_SHAPE = (30, 4) # 30 dias, 4 variables\n",
    "LATENT_DIM = 64       # Tamao del vector comprimido \n",
    "BATCH_SIZE = 64       # Procesar 64 muestras a la vez (Estandar para estabilidad)\n",
    "EPOCHS = 100          # Maximo de epocas \n",
    "MASKING_RATE = 0.2    # Romper el 20% de los datos para entrenar \n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "directorio = {\n",
    "    25037: {'Clasificacion': 'Seco', 'path': 'Seco/NR_25037',\n",
    "            'Direccion_data': './Tensorflow_data_escalada/Seco/NR_25037/train/data',\n",
    "            'direccion_tensor': './Tensorflow_data_escalada/Seco/NR_25037/train/tensor',\n",
    "            'direccion_modelo': './Modelos_Tensorflow/Seco/NR_25037/'},\n",
    "    \n",
    "    25033: {'Clasificacion': 'Templado', 'path': 'Templado/NR_25033', \n",
    "            'Direccion_data': './Tensorflow_data_escalada/Templado/NR_25033/train/data',\n",
    "            'direccion_tensor': './Tensorflow_data_escalada/Templado/NR_25033/train/tensor',\n",
    "            'direccion_modelo': './Modelos_Tensorflow/Templado/NR_25033/'},\n",
    "    \n",
    "    25046: {'Clasificacion': 'Tropical', 'path': 'Tropical/NR_25046', \n",
    "            'Direccion_data': './Tensorflow_data_escalada/Tropical/NR_25046/train/data',\n",
    "            'direccion_tensor': './Tensorflow_data_escalada/Tropical/NR_25046/train/tensor',\n",
    "            'direccion_modelo': './Modelos_Tensorflow/Tropical/NR_25046/'}\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for estacion, info in directorio.items():\n",
    "    ruta_data = info['Direccion_data']\n",
    "    ruta_tensor = info['direccion_tensor']\n",
    "    ruta_salida_modelo = info['direccion_modelo']\n",
    "    os.makedirs(ruta_salida_modelo, exist_ok=True)\n",
    "    \n",
    "    # Cargar datos de entrenamiento\n",
    "    X_train = np.load(os.path.join(ruta_tensor, 'train_data_tensor.npy'))\n",
    "    \n",
    "    X_train_ruido = X_train.copy()\n",
    "    mascara = np.random.rand(*X_train_ruido.shape) < MASKING_RATE\n",
    "    X_train_ruido[mascara] = 0\n",
    "    \n",
    "    #Limpiar sesin previa\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    # Encoder\n",
    "    encoded = Bidirectional(LSTM(LATENT_DIM, activation='relu', return_sequences=False))(inputs)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    \n",
    "    \n",
    "    decoded = RepeatVector(INPUT_SHAPE[0])(encoded)\n",
    "    \n",
    "    decoded = Bidirectional(LSTM(LATENT_DIM, activation='relu', return_sequences=True))(decoded)\n",
    "    decoded = Dropout(0.2)(decoded)\n",
    "    \n",
    "    outputs = TimeDistributed(Dense(INPUT_SHAPE[1]))(decoded)\n",
    "    \n",
    "    \n",
    "    modelo = Model(inputs, outputs)\n",
    "\n",
    "    modelo.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
    "    \n",
    "    modelo.summary()\n",
    "    \n",
    "    \n",
    "    camino_salida = os.path.join(ruta_salida_modelo, f'AE_BiLSTM_estacion_{estacion}.keras')\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(camino_salida, monitor='loss', save_best_only=True, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "    \n",
    "    print(f\"Entrenando modelo para la estacin {estacion}...\")\n",
    "    historia = modelo.fit(\n",
    "        X_train_ruido, X_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Guardar historia de entrenamiento\n",
    "    historia_path = os.path.join(ruta_salida_modelo, f'historia_entrenamiento_estacion_{estacion}.npy')\n",
    "    np.save(historia_path, historia.history)\n",
    "    # Graficar historia de entrenamiento\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(historia.history['loss'], label='Perdida de Entrenamiento')\n",
    "    plt.title(f'Historia de Entrenamiento - Estacin {estacion}')\n",
    "    plt.xlabel('Epocas')\n",
    "    plt.ylabel('Perdida (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True,alpha=0.3)\n",
    "    \n",
    "    plot_path = os.path.join(ruta_salida_modelo, f'historia_entrenamiento_estacion_{estacion}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    \n",
    "    print(f\"Modelo entrenado y guardado en {camino_salida}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3bd64",
   "metadata": {},
   "source": [
    "## Testing de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO TESTING DE IMPUTACION CON HORIZONTES\n",
      "Evaluando Estacion: 25037\n",
      "    Datos cargados: (5271, 30, 4)\n",
      "Evaluando Estacion: 25033\n",
      "    Datos cargados: (4688, 30, 4)\n",
      "Evaluando Estacion: 25046\n",
      "    Datos cargados: (6082, 30, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MASKING_RATE = 0.2  # 20% de datos borrados\n",
    "COLUMNAS = ['PRECIP', 'EVAP', 'TMAX', 'TMIN']\n",
    "\n",
    "# Definicin de Bins \n",
    "bins = [0, 3, 7, 31, 180, 365, 730, float('inf')]\n",
    "labels = ['1-3 Dias', '4-7 Dias', '8-31 Dias', '32-180 Dias', '181-365 Dias', '1-2 Aos', '>2 Aos']\n",
    "\n",
    "\n",
    "\n",
    "directorio = {\n",
    "    25037: {\n",
    "        'Clasificacion': 'Seco', \n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Seco/NR_25037/test/tensor', \n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Seco/NR_25037/scaler/scaler_test.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Seco/NR_25037/',\n",
    "        'direccion_salida_analisis': './data_analysis/test/Performance_metrics/Seco/NR_25037/'\n",
    "    },\n",
    "    25033: {\n",
    "        'Clasificacion': 'Templado', \n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Templado/NR_25033/test/tensor',\n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Templado/NR_25033/scaler/scaler_test.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Templado/NR_25033/',\n",
    "        'direccion_salida_analisis': './data_analysis/test/Performance_metrics/Templado/NR_25033/'\n",
    "    },\n",
    "    25046: {\n",
    "        'Clasificacion': 'Tropical', \n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Tropical/NR_25046/test/tensor',\n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Tropical/NR_25046/scaler/scaler_test.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Tropical/NR_25046/',\n",
    "        'direccion_salida_analisis': './data_analysis/test/Performance_metrics/Tropical/NR_25046/'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"INICIANDO TESTING DE IMPUTACION CON HORIZONTES\")\n",
    "\n",
    "for estacion, info in directorio.items():\n",
    "    print(f\"Evaluando Estacion: {estacion}\")\n",
    "    \n",
    "    ruta_tensor_base = info['direccion_tensor']\n",
    "\n",
    "    file_tensor = os.path.join(ruta_tensor_base, 'test_data_tensor.npy') \n",
    "    \n",
    "    \n",
    "    \n",
    "    ruta_scaler = info['direccion_scaler']\n",
    "    ruta_modelo = os.path.join(info['direccion_modelo'], f'AE_BiLSTM_estacion_{estacion}.keras')\n",
    "    \n",
    "    X_test = np.load(file_tensor) \n",
    "    scaler = joblib.load(ruta_scaler)\n",
    "    modelo = tf.keras.models.load_model(ruta_modelo)\n",
    "    \n",
    "    print(f\"    Datos cargados: {X_test.shape}\")\n",
    "    \n",
    "    X_test_ruido = X_test.copy()\n",
    "    mascara_booleana = np.random.rand(*X_test_ruido.shape) < MASKING_RATE\n",
    "    X_test_ruido[mascara_booleana] = 0 # Borramos datos\n",
    "    \n",
    "    X_pred_scaled = modelo.predict(X_test_ruido, batch_size=BATCH_SIZE, verbose=0)\n",
    "    \n",
    "    # N = muestras, T = pasos tiempo, F = features\n",
    "    N, T, F = X_test.shape\n",
    "    \n",
    "    #Aplanamiento 2D para poder usar el scaler y crear DataFrames\n",
    "    X_real_flat = X_test.reshape(-1, F)\n",
    "    X_pred_flat = X_pred_scaled.reshape(-1, F)\n",
    "    mascara_flat = mascara_booleana.reshape(-1, F) \n",
    "    \n",
    "    # Inverse Transform (0-1 -> Valores Reales)\n",
    "    X_real_inv = scaler.inverse_transform(X_real_flat)\n",
    "    X_pred_inv = scaler.inverse_transform(X_pred_flat)\n",
    "    \n",
    "    #DF para poder filtrar por mscara y por Horizontes\n",
    "    df_maestro = pd.DataFrame(index=range(len(X_real_inv)))\n",
    "    \n",
    "\n",
    "    df_maestro['Dia_Test'] = (df_maestro.index // T) + 1\n",
    "    df_maestro['Rango'] = pd.cut(df_maestro['Dia_Test'], bins=bins, labels=labels)\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    for i, col in enumerate(COLUMNAS):\n",
    "        metrics_summary = []\n",
    "        estacion_dir = os.path.join(info['direccion_salida_analisis'])\n",
    "        output_col_dir = os.path.join(estacion_dir, col)\n",
    "        os.makedirs(output_col_dir, exist_ok=True)\n",
    "        \n",
    "        # Extraer datos de la columna actual\n",
    "        col_real = X_real_inv[:, i]\n",
    "        col_pred = X_pred_inv[:, i]\n",
    "        col_mask = mascara_flat[:, i] # True si fue borrado\n",
    "        \n",
    "        df_maestro[f'{col}_Real'] = col_real\n",
    "        df_maestro[f'{col}_Pred'] = col_pred\n",
    "        df_maestro[f'{col}_IsMasked'] = col_mask\n",
    "        \n",
    "\n",
    "        df_eval = df_maestro[df_maestro[f'{col}_IsMasked'] == True].copy()\n",
    "        \n",
    "        if df_eval.empty:\n",
    "            print(f\"No se enmascararon datos para {col}\")\n",
    "            continue\n",
    "            \n",
    "        # Bucle por Horizontes \n",
    "        for label in labels:\n",
    "            subset = df_eval[df_eval['Rango'] == label]\n",
    "            count = len(subset)\n",
    "            \n",
    "            if count > 0:\n",
    "                y_true = subset[f'{col}_Real']\n",
    "                y_pred = subset[f'{col}_Pred']\n",
    "                \n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y_true, y_pred)\n",
    "                \n",
    "                mask_nz = y_true != 0\n",
    "                if np.sum(mask_nz) > 0:\n",
    "                    mape = np.mean(np.abs((y_true[mask_nz] - y_pred[mask_nz]) / y_true[mask_nz])) * 100\n",
    "                else:\n",
    "                    mape = 0.0\n",
    "            else:\n",
    "                mse, rmse, mae, mape = 0, 0, 0, 0\n",
    "            \n",
    "            metrics_summary.append({\n",
    "                'Horizonte': label,\n",
    "                'MSE': round(mse, 4),\n",
    "                'RMSE': round(rmse, 4),\n",
    "                'MAE': round(mae, 4),\n",
    "                'MAPE': round(mape, 4),\n",
    "                'Count': count\n",
    "            })\n",
    "            \n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(col_real[:100], label='Real', color='blue', alpha=0.6)\n",
    "        plt.plot(col_pred[:100], label='Imputado', color='orange', linestyle='--', alpha=0.8)\n",
    "\n",
    "        huecos_idx = np.where(col_mask[:100])[0]\n",
    "        plt.scatter(huecos_idx, col_pred[:100][huecos_idx], color='red', s=15, label='Hueco Rellenado', zorder=5)\n",
    "        \n",
    "        plt.title(f'Test Imputacion: {col} - Estacion {estacion}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(output_col_dir, f'plot_test_{col}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        df_metrics = pd.DataFrame(metrics_summary)\n",
    "        path_csv = os.path.join(output_col_dir,'tensorflow_test_metrics_horizonte.csv')\n",
    "        df_metrics.to_csv(path_csv, index=False)\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.axis('off')\n",
    "        cols_show = ['Horizonte', 'MSE', 'RMSE', 'MAE', 'MAPE', 'Count']\n",
    "        tbl = ax.table(cellText=df_metrics[cols_show].values, colLabels=cols_show, loc='center', cellLoc='center')\n",
    "        tbl.scale(1, 1.4)\n",
    "        plt.savefig(os.path.join(output_col_dir, f'table_metrics_{col}.png'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec62fc0",
   "metadata": {},
   "source": [
    "### Validacion Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO VALIDACIN TENSORFLOW CON HORIZONTES ---\n",
      "\n",
      "--> Validando Estacin: 25037 (Seco)\n",
      "    Data shape: (2622, 30, 4)\n",
      "    [OK] Reportes generados en ./data_analysis/val/Performance_metrics/Seco/NR_25037/\n",
      "\n",
      "--> Validando Estacin: 25033 (Templado)\n",
      "    Data shape: (2329, 30, 4)\n",
      "    [OK] Reportes generados en ./data_analysis/val/Performance_metrics/Templado/NR_25033/\n",
      "\n",
      "--> Validando Estacin: 25046 (Tropical)\n",
      "    Data shape: (3026, 30, 4)\n",
      "    [OK] Reportes generados en ./data_analysis/val/Performance_metrics/Tropical/NR_25046/\n",
      "\n",
      "--- PROCESO TERMINADO ---\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MASKING_RATE = 0.2  \n",
    "COLUMNAS = ['PRECIP', 'EVAP', 'TMAX', 'TMIN']\n",
    "\n",
    "bins = [0, 3, 7, 31, 180, 365, 730, float('inf')]\n",
    "labels = ['1-3 Dias', '4-7 Dias', '8-31 Dias', '32-180 Dias', '181-365 Dias', '1-2 Aos', '>2 Aos']\n",
    "\n",
    "directorio = {\n",
    "    25037: {\n",
    "        'Clasificacion': 'Seco',\n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Seco/NR_25037/val/tensor',\n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Seco/NR_25037/scaler/scaler_val.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Seco/NR_25037/',\n",
    "        'direccion_salida_analisis': './data_analysis/val/Performance_metrics/Seco/NR_25037/'\n",
    "    },\n",
    "    25033: {\n",
    "        'Clasificacion': 'Templado',\n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Templado/NR_25033/val/tensor',\n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Templado/NR_25033/scaler/scaler_val.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Templado/NR_25033/',\n",
    "        'direccion_salida_analisis': './data_analysis/val/Performance_metrics/Templado/NR_25033/'\n",
    "    },\n",
    "    25046: {\n",
    "        'Clasificacion': 'Tropical',\n",
    "        'direccion_tensor': './Tensorflow_data_escalada/Tropical/NR_25046/val/tensor',\n",
    "        'direccion_scaler': './Tensorflow_data_escalada/Tropical/NR_25046/scaler/scaler_val.joblib.pkl',\n",
    "        'direccion_modelo': './Modelos_Tensorflow/Tropical/NR_25046/',\n",
    "        'direccion_salida_analisis': './data_analysis/val/Performance_metrics/Tropical/NR_25046/'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"--- INICIANDO VALIDACIN TENSORFLOW CON HORIZONTES ---\")\n",
    "\n",
    "for station_id, info in directorio.items():\n",
    "    print(f\"\\n--> Validando Estacin: {station_id} ({info['Clasificacion']})\")\n",
    "    \n",
    "    # 1. Rutas\n",
    "    path_tensor_val = info['direccion_tensor'] + '_val.npy' # Asumiendo sufijo _val.npy\n",
    "    # Si no existe, intentar con la estructura de carpetas\n",
    "    if not os.path.exists(path_tensor_val):\n",
    "         path_tensor_val = os.path.join(info['direccion_tensor'], 'val_data_tensor.npy')\n",
    "\n",
    "    path_scaler = info['direccion_scaler']\n",
    "    path_model = os.path.join(info['direccion_modelo'], f'AE_BiLSTM_estacion_{station_id}.keras')\n",
    "    path_output_base = info['direccion_salida_analisis']\n",
    "    \n",
    "    os.makedirs(path_output_base, exist_ok=True)\n",
    "    \n",
    "    # Validaciones bsicas de existencia\n",
    "    if not os.path.exists(path_tensor_val):\n",
    "        print(f\"    [SKIP] No existe tensor: {path_tensor_val}\")\n",
    "        continue\n",
    "    if not os.path.exists(path_model):\n",
    "        print(f\"    [SKIP] No existe modelo: {path_model}\")\n",
    "        continue\n",
    "\n",
    "    # 2. Cargar Datos\n",
    "    X_val_scaled = np.load(path_tensor_val)\n",
    "    model = tf.keras.models.load_model(path_model)\n",
    "    scaler = joblib.load(path_scaler)\n",
    "    \n",
    "    print(f\"    Data shape: {X_val_scaled.shape}\")\n",
    "\n",
    "    # 3. Masking y Prediccin\n",
    "    X_val_noisy = X_val_scaled.copy()\n",
    "    mask_boolean = np.random.rand(*X_val_scaled.shape) < MASKING_RATE\n",
    "    X_val_noisy[mask_boolean] = 0 \n",
    "    \n",
    "    X_pred_scaled = model.predict(X_val_noisy, batch_size=BATCH_SIZE, verbose=0)\n",
    "    \n",
    "    # 4. Des-escalar y Aplanar\n",
    "    N, T, F = X_val_scaled.shape\n",
    "    \n",
    "    # Aplanamos para anlisis vectorial\n",
    "    X_real_flat = scaler.inverse_transform(X_val_scaled.reshape(-1, F))\n",
    "    X_pred_flat = scaler.inverse_transform(X_pred_scaled.reshape(-1, F))\n",
    "    mask_flat = mask_boolean.reshape(-1, F)\n",
    "    \n",
    "    # 5. Crear DataFrame Maestro para Anlisis por Horizonte\n",
    "    total_points = len(X_real_flat)\n",
    "    \n",
    "\n",
    "    df_analysis = pd.DataFrame(index=range(total_points))\n",
    "    df_analysis['Dia_Simulado'] = (df_analysis.index // T) + 1 \n",
    "    df_analysis['Rango'] = pd.cut(df_analysis['Dia_Simulado'], bins=bins, labels=labels)\n",
    "\n",
    "    for i, col in enumerate(COLUMNAS):\n",
    "        # Crear carpeta para la variable\n",
    "        path_col_output = os.path.join(path_output_base, col)\n",
    "        os.makedirs(path_col_output, exist_ok=True)\n",
    "        \n",
    "        # Extraer datos de la columna\n",
    "        col_real = X_real_flat[:, i]\n",
    "        col_pred = X_pred_flat[:, i]\n",
    "        col_mask = mask_flat[:, i]\n",
    "        \n",
    "        # Aadir al DF de anlisis\n",
    "        df_analysis['Real'] = col_real\n",
    "        df_analysis['Pred'] = col_pred\n",
    "        df_analysis['IsMasked'] = col_mask\n",
    "        \n",
    "        #Solo analizar lo que fue enmascarado \n",
    "        df_masked = df_analysis[df_analysis['IsMasked'] == True].copy()\n",
    "        \n",
    "        metrics_by_horizon = []\n",
    "        \n",
    "        # Bucle por horizontes\n",
    "        for label in labels:\n",
    "            subset = df_masked[df_masked['Rango'] == label]\n",
    "            count = len(subset)\n",
    "            \n",
    "            if count > 0:\n",
    "                y_true = subset['Real']\n",
    "                y_pred = subset['Pred']\n",
    "                \n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y_true, y_pred)\n",
    "                \n",
    "                # MAPE seguro\n",
    "                mask_nz = y_true != 0\n",
    "                if np.sum(mask_nz) > 0:\n",
    "                    mape = np.mean(np.abs((y_true[mask_nz] - y_pred[mask_nz]) / y_true[mask_nz]))\n",
    "                else:\n",
    "                    mape = 0.0\n",
    "            else:\n",
    "                mse, rmse, mae, mape = 0, 0, 0, 0\n",
    "            \n",
    "            metrics_by_horizon.append({\n",
    "                'Horizonte': label,\n",
    "                'MSE': round(mse, 4),\n",
    "                'RMSE': round(rmse, 4),\n",
    "                'MAE': round(mae, 4),\n",
    "                'MAPE': round(mape, 4),\n",
    "                'Count': count\n",
    "            })\n",
    "            \n",
    "        # Guardar CSV de Mtricas\n",
    "        df_metrics = pd.DataFrame(metrics_by_horizon)\n",
    "        df_metrics.to_csv(os.path.join(path_col_output, 'metrics_horizonte.csv'), index=False)\n",
    "        \n",
    "        # Guardar Imagen de Tabla\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.axis('off')\n",
    "        tbl = ax.table(cellText=df_metrics.values, colLabels=df_metrics.columns, loc='center', cellLoc='center')\n",
    "        tbl.scale(1, 1.4)\n",
    "        plt.title(f\"Validacin por Horizonte: {col}\")\n",
    "        plt.savefig(os.path.join(path_col_output, 'tabla_metricas.png'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Guardar Grfica de Barras (RMSE)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_data = df_metrics[df_metrics['Count'] > 0]\n",
    "        if not plot_data.empty:\n",
    "            bars = plt.bar(plot_data['Horizonte'], plot_data['RMSE'], color='lightgreen', edgecolor='black')\n",
    "            plt.title(f'RMSE por Horizonte - {col} - {station_id}')\n",
    "            plt.xticks(rotation=45)\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}', ha='center', va='bottom')\n",
    "        plt.savefig(os.path.join(path_col_output, 'RMSE_bar_plot.png'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # Guardar Grfica de Lnea\n",
    "        limit = 150\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(col_real[:limit], label='Real', color='blue', alpha=0.4)\n",
    "        plt.plot(col_pred[:limit], label='Reconstruccin IA', color='orange', linestyle='--', alpha=0.8)\n",
    "        \n",
    "        # Puntos rojos en huecos\n",
    "        indices_borrados = np.where(col_mask[:limit])[0]\n",
    "        if len(indices_borrados) > 0:\n",
    "             plt.scatter(indices_borrados, col_pred[:limit][indices_borrados], color='red', s=20, label='Imputado', zorder=5)\n",
    "             \n",
    "        plt.title(f'Reconstruccin vs Realidad: {col}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(path_col_output, 'plot_linea_comparativa.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"    [OK] Reportes generados en {path_output_base}\")\n",
    "\n",
    "print(\"\\n--- PROCESO TERMINADO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1bc6b",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc96f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
